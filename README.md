# ü§ñ ChatBot

Ce projet utilise un **PC "serveur"** √©quip√© d‚Äôun **GPU** sous **Windows 11** avec **WSL2**, ainsi qu‚Äôun **PC portable "client"** pour le d√©veloppement.

- Le **serveur** ex√©cute PyTorch et CUDA.  
- Le **client** utilise **PyCharm** pour le d√©veloppement.  
- Les deux machines sont reli√©es via **SSH** avec **Tailscale**, car elles ne sont pas sur le m√™me r√©seau.

## ‚öôÔ∏è Commandes utiles

V√©rifier la d√©tection de CUDA et du GPU :
```bash
python -c "import torch; print('CUDA disponible:', torch.cuda.is_available(), 'Nom du GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Aucun GPU')"
```

Activer l‚Äôenvironnement sur la tour
```bash
source ~/pytorch_env/bin/activate
```

Surveiller l‚Äôutilisation du GPU:
```bash
watch -n 1 gpustat -cp
```
