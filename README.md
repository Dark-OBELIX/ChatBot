# ðŸ¤– ChatBot

Ce projet utilise un **PC "serveur"** Ã©quipÃ© dâ€™un **GPU** sous **Windows 11** avec **WSL2**, ainsi quâ€™un **PC portable "client"** pour le dÃ©veloppement.

- Le **serveur** exÃ©cute PyTorch et CUDA.  
- Le **client** utilise **PyCharm** pour le dÃ©veloppement.  
- Les deux machines sont reliÃ©es via **SSH** avec **Tailscale**, car elles ne sont pas sur le mÃªme rÃ©seau.

## âš™ï¸ Commandes utiles

VÃ©rifier la dÃ©tection de CUDA et du GPU :
```bash
python -c "import torch; print('CUDA disponible:', torch.cuda.is_available(), 'Nom du GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Aucun GPU')"
```

Activer lâ€™environnement sur la tour
```bash
source ~/pytorch_env/bin/activate
```

Surveiller lâ€™utilisation du GPU:
```bash
watch -n 1 gpustat -cp
```

Lancer le script : dans le repo : 
```bash
run_remote_script main.py
```

Alias :
```bash
nano ~/.bashrc

alias run_remote_script='f() { \
  rsync -avz "/mnt/c/Users/hugol/OneDrive/Documents/0_Perso/0_2_Projets_perso/ChatBot/scripts/" sidiouslinux@100.88.42.33:~/projects/pytorch_projects/scrip>  ssh sidiouslinux@100.88.42.33 "cd ~/projects/pytorch_projects && ./run.sh scripts/$1"; \
}; f'

source ~/.bashrc
```
