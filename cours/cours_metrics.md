# ğŸ“Š Cours : Notions clÃ©s dans l'entraÃ®nement dâ€™un rÃ©seau de neurones

## 1. Ã‰poque (Epoch)

Une **Ã©poque** correspond Ã  **un passage complet de lâ€™ensemble des donnÃ©es dâ€™entraÃ®nement** Ã  travers le modÃ¨le.  
Autrement dit, lorsque toutes les donnÃ©es ont Ã©tÃ© utilisÃ©es une fois pour ajuster les poids, on dit quâ€™une Ã©poque est terminÃ©e.

### ğŸŒ€ Exemple :
Si ton jeu de donnÃ©es contient 1 000 Ã©chantillons et que tu les envoies au modÃ¨le par lots de 100 (batch size = 100),  
alors **une Ã©poque = 10 itÃ©rations** (1000 / 100 = 10).

ğŸ‘‰ En gÃ©nÃ©ral, on entraÃ®ne un modÃ¨le sur plusieurs Ã©poques (ex. : 50 ou 100) pour lui permettre de mieux apprendre.

---

## 2. Fonction de perte (Loss Function)

La **fonction de perte** (ou *loss*) mesure **lâ€™Ã©cart entre la sortie prÃ©dite et la sortie rÃ©elle**.  
Câ€™est **la quantitÃ© que le modÃ¨le cherche Ã  minimiser** pendant lâ€™apprentissage.

### ğŸ”§ Exemples de fonctions de perte :
| Type de tÃ¢che | Fonction de perte courante | Description |
|----------------|-----------------------------|--------------|
| RÃ©gression | Erreur quadratique moyenne (MSE) | Mesure la distance entre les valeurs rÃ©elles et prÃ©dites |
| Classification binaire | Binary Cross-Entropy | Compare les probabilitÃ©s prÃ©dites Ã  la vÃ©ritÃ© terrain |
| Classification multi-classes | Categorical Cross-Entropy | GÃ©nÃ©ralisation pour plusieurs classes |

### ğŸ§® Exemple (Binary Cross-Entropy) :
\[
L = - \frac{1}{N} \sum_{i=1}^N [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]
\]

---

## 3. PrÃ©cision (Accuracy)

La **prÃ©cision (accuracy)** reprÃ©sente le **pourcentage de prÃ©dictions correctes** sur lâ€™ensemble des donnÃ©es.  

### ğŸ§® Formule :
\[
\text{Accuracy} = \frac{\text{Nombre de bonnes prÃ©dictions}}{\text{Nombre total d'Ã©chantillons}}
\]

### ğŸ§  Exemple :
Si ton modÃ¨le a correctement prÃ©dit 90 Ã©chantillons sur 100,  
\( \text{Accuracy} = 0.90 \) â†’ soit **90 % de prÃ©cision**.

âš ï¸ Attention : lâ€™accuracy nâ€™est pas toujours reprÃ©sentative, notamment si les classes sont dÃ©sÃ©quilibrÃ©es.

---

## 4. Score F1 (F1-Score)

Le **F1-score** est une **moyenne harmonique** entre la **prÃ©cision (precision)** et le **rappel (recall)**.  
Il est souvent utilisÃ© lorsque les classes sont dÃ©sÃ©quilibrÃ©es.

### ğŸ§® Formules :
\[
\text{Precision} = \frac{\text{Vrais positifs}}{\text{Vrais positifs} + \text{Faux positifs}}
\]
\[
\text{Recall} = \frac{\text{Vrais positifs}}{\text{Vrais positifs} + \text{Faux nÃ©gatifs}}
\]
\[
\text{F1} = 2 * \frac{\text{Precision} * \text{Recall}}{\text{Precision} + \text{Recall}}
\]

### ğŸ§  Exemple :
- Precision = 0.8  
- Recall = 0.6  
- F1 = 2 Ã— (0.8Ã—0.6)/(0.8+0.6) = 0.6857 â†’ **â‰ˆ 68,6 %**

---

## 5. Suivi pendant lâ€™entraÃ®nement

Durant lâ€™entraÃ®nement dâ€™un rÃ©seau de neurones, on suit souvent plusieurs mÃ©triques :

| Ã‰poque | Perte (Loss) | Accuracy | F1-score |
|:------:|:-------------:|:---------:|:---------:|
| 1 | 0.89 | 0.62 | 0.58 |
| 5 | 0.45 | 0.79 | 0.76 |
| 10 | 0.23 | 0.90 | 0.88 |

ğŸ”¹ La **perte** doit gÃ©nÃ©ralement **diminuer** au fil des Ã©poques.  
ğŸ”¹ Les **mÃ©triques de performance (Accuracy, F1)** doivent **augmenter** jusquâ€™Ã  un point de stabilisation.  

---

## 6. Courbes dâ€™apprentissage

Les courbes permettent de **visualiser la progression du modÃ¨le** :

- **Loss vs Epoch** â†’ pour vÃ©rifier la convergence.  
- **Accuracy vs Epoch** â†’ pour voir si le modÃ¨le apprend bien ou sâ€™il sur-apprend (*overfitting*).

ğŸ“ˆ Exemple attendu :
- La courbe de *loss* descend rapidement puis se stabilise.  
- La courbe dâ€™*accuracy* monte jusquâ€™Ã  un plateau.  

---

## 7. RÃ©sumÃ©

> ğŸ”¹ **Ã‰poque (epoch)** : un passage complet sur le jeu de donnÃ©es.  
> ğŸ”¹ **Loss** : mesure de lâ€™erreur Ã  minimiser.  
> ğŸ”¹ **Accuracy** : proportion de bonnes prÃ©dictions.  
> ğŸ”¹ **F1-score** : Ã©quilibre entre prÃ©cision et rappel, utile pour les classes dÃ©sÃ©quilibrÃ©es.

---

## 8. Bonnes pratiques

- Surveille toujours la **courbe de validation** (validation loss/accuracy).  
- ArrÃªte lâ€™entraÃ®nement avant le sur-apprentissage (technique dâ€™**early stopping**).  
- Utilise le **F1-score** plutÃ´t que lâ€™accuracy quand les classes sont inÃ©gales.  
- Garde les **mÃ©triques par Ã©poque** pour comprendre la progression du modÃ¨le.

---

ğŸ§  En rÃ©sumÃ© :  
Ces mÃ©triques sont les **indicateurs essentiels** pour Ã©valuer et amÃ©liorer la qualitÃ© dâ€™un rÃ©seau de neurones comme ton **MLP**.
