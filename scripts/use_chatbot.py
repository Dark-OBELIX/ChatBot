# scripts/use_chatbot.py
import os
import sys
import torch
import spacy

# âœ… Permet dâ€™importer config.py et autres modules depuis la racine
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.data_chatbot import data
from scripts.monitoring import log_misclassified
from config import SHOW_PROBABILITIES, ASK_FEEDBACK, CONFIDENCE_THRESHOLD, ENABLE_MONITORING

# --- Initialisation spaCy (mÃªme modÃ¨le que pour l'entraÃ®nement) ---
print("ðŸ”¤ Initialisation du modÃ¨le linguistique franÃ§ais (spaCy)...")
try:
    nlp = spacy.load("fr_core_news_sm")
except OSError:
    from spacy.cli import download
    print("âš™ï¸  ModÃ¨le 'fr_core_news_sm' introuvable. TÃ©lÃ©chargement en cours...")
    download("fr_core_news_sm")
    nlp = spacy.load("fr_core_news_sm")


# --- Fonction de prÃ©traitement identique Ã  l'entraÃ®nement ---
def clean_and_lemmatize(text):
    """
    Nettoie et lemmatise une phrase utilisateur :
    - convertit en minuscules
    - conserve les stopwords
    - garde uniquement les mots alphabÃ©tiques
    """
    text = text.lower().strip()
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if token.is_alpha])


# --- Boucle principale du chatbot ---
def use_model(model, vectorizer):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    print("\nðŸ¤– Chatbot prÃªt ! Tapez 'quit' pour quitter.\n")

    while True:
        user_input = input("Vous : ").strip()
        if not user_input or len(user_input.replace(" ", "")) == 0:
            print("âš ï¸ EntrÃ©e vide ignorÃ©e.")
            continue

        # âœ… PrÃ©traitement identique Ã  l'entraÃ®nement
        processed_text = clean_and_lemmatize(user_input)

        # Vectorisation
        vec = vectorizer.transform([processed_text]).toarray()
        x = torch.tensor(vec, dtype=torch.float32).to(device)

        # PrÃ©diction
        with torch.no_grad():
            output = model(x)
            probs = torch.softmax(output, dim=1).cpu().numpy().flatten()

        predicted_index = int(probs.argmax())
        confidence = float(probs[predicted_index])

        # Affichage des probabilitÃ©s (optionnel)
        if SHOW_PROBABILITIES:
            print("\n--- DÃ©tails des probabilitÃ©s ---")
            for i, p in enumerate(probs):
                print(f"{i}: {data[i]['answer']} -> {p*100:.2f}%")

        # Gestion des faibles confiances
        if confidence < CONFIDENCE_THRESHOLD:
            print(f"Chatbot : Je ne suis pas sÃ»r ðŸ¤” (confiance={confidence*100:.1f}%)")
            if ENABLE_MONITORING:
                log_misclassified(user_input, predicted_index, confidence)
            continue

        # RÃ©ponse principale
        answer = data[predicted_index]["answer"]
        action = data[predicted_index]["action_index"]
        print(f"Chatbot : {answer} (confiance={confidence*100:.2f}%)")

        # Feedback utilisateur (optionnel)
        if ASK_FEEDBACK:
            feedback = input("Ã‰tait-ce la bonne rÃ©ponse ? (o/n) : ").strip().lower()
            if feedback == "n" and ENABLE_MONITORING:
                correct_label = input("âž¡ï¸  Quelle Ã©tait la bonne intention (0â€“12) ? : ").strip()
                log_misclassified(user_input, predicted_index, confidence, correct_label)

        # Action spÃ©ciale (ex: fermeture)
        if action == 1:
            print("ðŸ”š Action spÃ©ciale dÃ©tectÃ©e : fermeture du programme.")
            break
